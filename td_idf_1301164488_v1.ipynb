{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "td/idf_1301164488_v1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wf7tHn03SoF3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5vMp2DnUp7x",
        "colab_type": "text"
      },
      "source": [
        "# Importing Data Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iT6mD-TQN2SQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datatext = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0Y9Nf-PUDbH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datatext1 = '''Catteleya Walkerina. Found in Goias, Minas Gerais, Espirito Santo and Sao Paulo states of Brazil on giant old trees on rocky limestone plateaus or small trees or moist rocks near streams at elevations up to 2000 meters with jointed, bulbous or shortly fusiform, shiny yellow pseudobulbs carrying a single [rarely 2], apical, elliptic or ovate, leathery leaf that is rounded apically and blooms mostly in the fall but can occur at other times [see varieties below] on a 3\" [7.5 cm] long, arcuate, single to few [1 to 3] flowered inflorescence carrying fragrant vanilla to cinnamon scented flowers that open very flat. This species and C. nobilor are the only Cattleya that the terminal, shorter, 1 to few flowered inflorescence arises from the base of the pseudobulb seemingly as a new growth.'''\n",
        "datatext.append('''Ruby Lipped Cattleya. Found in Venezuela and Maranhao, Piaui, Ceara, Pernambuco and Alagoas states of Brazil at elevations of 600 to 900 meters as a warm growing, variable sized epiphyte with club-shaped, slightly compressed pseudobulbs subtended by several greenish, thin textured sheaths and carrying a single, apical, oblong, obtuse, coriaceous leaf that blooms mostly in the fall and early winter on a short, few [2 to 5] flowered inflorescence subtended by a double, leathery sheath and carrying spicy, aromatic to clove scented flowers.''')\n",
        "datatext.append('''Cattleya maxima. A medium sized, cool to warm growing, unifoliate, epiphyte and occasional lithophyte from Venezuela, Colombia, Ecuador and northern coastal Peru that is found at elevations of 10 to 1500 meters in seasonally dry, coastal forests with clavate, lightly complante, sulcate pseudobulbs subtended by several, imbricating, nonfoliaceous sheaths and a single, apical, oblong or narrowly elliptic-oblong, clasping, obtuse, minutely bilobed, thickly coriaceous leaf and blooms in the fall through the winter on a terminal, to 12\" [30 cm] long, erect or arching, few to several flowered, racemose inflorescence arising on a mature pseudobulb subtended with a large, basal, elongate sheath from which arise 3 to 15, long-lived, fragrant helioptrope to sweet pea scented, somewhat heavy textured flowers that are held just at or above leaf height.''')\n",
        "datatext.append('''Intermedia Cattleya. Found in Sao Paulo, Santa Catarina and Rio Grande do Sul states of Brazil, Uruguay and Argentina in the Atlantic coastal forest on rocks and small trees near the sea or streams as a small to medium sized, cool to warm growing orchid with slender, cylindric pseudobulbs with several, tubular, scarious bracts enveloping it and 2 to 4, apical, subopposite leaves that blooms in the spring or summer on a terminal, short to long stalked, few to several [3 to 7] flowered inflorecence with minute floral bracts and subtended by a conduplicate sheath all arising on a newly matured pseudobulb with heavy textured, long-lived, fragrant floral scented , color variable flowers. The in situ shots are from Boia Ceia', Sao Paulo State, Brasil. These plants are plentiful in their specific environment which encompasses the exact area that condos by the sea are most often built. The sea gives way to the sand and then the sand gives way to vines and grasses and then to small bushes and then begins the hammock of stunted hardwoods with swales of tidal saltwater and freshwater runnoff. This area is extremely humid and hot and is bathed by spray from the crashing surf less than 20 yards away. Cattleya intermedia is found in these hammocks in vast quanities. I saw close to 500 just in a 30 acre area. Almost all were on trees at or just above eye-level. The branches and trunks were extremely damp and had lichen and mosses. There was a lot of standing water with mosquitoes and bromeliads were everywhere. All discussions about this species being extinct or rare in the wild are hogwash and it is not threatened by over-collection as stated by Bechtel-Cribb in the Manual of Cultivated Orchids.''')\n",
        "datatext.append('''The Noble Cattleya. Found in Matto Grossa, DF and Goias State of Brazil as well as Santa Cruz Bolivia and Paraguay along rivers on roughbarked trees at the edges of high cliffs in full sun and with ample air circulation at elevations of 170 to 700 meters as a small to medium sized, hot to warm growing epiphyte. This species is characterized by having ellipsoid pseudobulbs carrying 2 apical, elliptic to elliptic-oblong, coriaceous leaves and blooms on a to 3 1/8\" [to 8 cm] long, slender, 1 to few flowered inflorescence with up to 5 extremely [vanilla citron] fragrant flowers. This species is always bifoliate and can be distinguished from Cattleya walkeriana by this fact alone as C walkeriana has only one. This area has a distinct wet and dry period and it is quite hot. A five month drier rest from November through March is reccomended. The var amaliae pictured above is cooler growing and comes from the Brazilian states of Goias and Tocantins at elevations to 900 meters on rough barked trees.''')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UmdwOKpN4oh",
        "colab_type": "code",
        "outputId": "8c529b1d-6e0c-40ee-e3ea-f7b52e13df83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "datatext"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-Dn0sBvOKUm",
        "colab_type": "text"
      },
      "source": [
        "# Remove Special Strings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYnX_M4lOAfM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_string_special_characters(s):\n",
        "  \n",
        "  #for dt in datatext:\n",
        "    # Replace special character with ''\n",
        "    stripped = re.sub('[^\\w\\s]','',s)\n",
        "    stripped = re.sub('_','',stripped)\n",
        "\n",
        "    #change any whitespaces to one space\n",
        "    stripped = re.sub('\\s','', stripped)\n",
        "\n",
        "    #remove start and end white spaces\n",
        "    stripped = stripped.strip()\n",
        "\n",
        "    return stripped"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nX-TfuvQRFB2",
        "colab_type": "text"
      },
      "source": [
        "# Creating the doc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OflA-5MwQ1HK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_doc(sent):\n",
        "  # Splitting text into senteces and considering each sentences as a document\n",
        "  # calculate the word\n",
        "\n",
        "  info_doc = []\n",
        "  i = 0\n",
        "  for sent in text_sents_clean:\n",
        "    i += 1\n",
        "    count = count_words(sent)\n",
        "    temp = {'doc_id': i, 'doc_length': count}\n",
        "    info_doc.append(temp)\n",
        "  return info_doc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1y86SY3SWRm",
        "colab_type": "text"
      },
      "source": [
        "# Calculate TF and IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5Lz8fQxSZEh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#sent = sentences\n",
        "\n",
        "def count_word(sent):\n",
        "  count = 0\n",
        "  words = word_tokenize(sent)\n",
        "  for word in word:\n",
        "    count += 1\n",
        "  return count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPpils4tStZq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_freq_dict(sents):\n",
        "  i = 0\n",
        "  freqDict_list = []\n",
        "  for sent in sents:\n",
        "    i += 1\n",
        "    freq_dict = {}\n",
        "    words = word_tokenize(sent)\n",
        "    for word in words:\n",
        "      word = word.lower() #get uppercase to all word become lowercase\n",
        "      if word in freq_dict:\n",
        "        freq_dict[word] += 1\n",
        "      else:\n",
        "        freq_dict[word] = 1\n",
        "      temp = {'doc_id': i, 'freq_dict': freq_dict}\n",
        "    freqDict_list.append(temp)\n",
        "  return freqDict_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Em2t2tv7UNio",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def computeTF(info_doc, freqDict_list):\n",
        "  scoresTF = []\n",
        "  for tempDict in freqDict_list:\n",
        "    id = tempDict['doc_id']\n",
        "    for k in tempDict['freq_dict']:\n",
        "      temp = {'doc_id': id,\n",
        "              'scoreTF' : tempDict['freq_dict'][k] / info_doc[id-1]['doc_length'], 'key': k}\n",
        "      scoresTF.append(temp)\n",
        "  \n",
        "  return scoresTF\n",
        "            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Saavrf8vVrrN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def computeTFIDF(info_doc, freqDict_list):\n",
        "  scoresIDF = []\n",
        "  counter = 0\n",
        "  for dict in freqDict_list:\n",
        "    counter += 1\n",
        "    for k in dict['freq_dict'].keys():\n",
        "      count = sum([k in tempDict['freq_dict'] for tempDict in freqDict_list])\n",
        "      temp = {'doc_id' : counter, 'scoreIDF' : mathlog(len(doc_info)/count), 'key': k}\n",
        "\n",
        "      scoresIDF.append(temp)\n",
        "    \n",
        "  return scoresIDF"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAj27it2YUl_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def computeTFIDF(scoresTF, scoresIDF):\n",
        "  scoresTFIDF = []\n",
        "  for j in scoresIDF:\n",
        "    for i in scoresTF:\n",
        "      if j['key'] == i['key'] and j['doc_id'] == i['doc_id']:\n",
        "        temp = {'doc_id' : j['doc_id'],\n",
        "                'scoreTFIDF' : j['scoreIDF']*i['TF_score'],\n",
        "                'key': i['key']}\n",
        "    \n",
        "    scoresTFIDF.append(temp)\n",
        "\n",
        "  return scoresTFIDF"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yg-M0jZZa2KR",
        "colab_type": "code",
        "outputId": "aec4e83e-683b-460e-b4ad-9c941d63d7b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 613
        }
      },
      "source": [
        "text_sents = sent_tokenize(datatext1)\n",
        "text_sents_clean = [remove_string_special_characters(s) for s in text_sents]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "LookupError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-57ca349ab8e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtext_sents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatatext1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtext_sents_clean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mremove_string_special_characters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext_sents\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPunkt\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \"\"\"\n\u001b[0;32m---> 94\u001b[0;31m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tokenizers/punkt/{0}.pickle'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m     \u001b[0;31m# Load the resource.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 834\u001b[0;31m     \u001b[0mopened_resource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    835\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'raw'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(resource_url)\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'nltk'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    953\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'file'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0;31m# urllib might not use mode='rb', so handle this one ourselves:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'*'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/lib/nltk_data'\n    - ''\n**********************************************************************\n"
          ]
        }
      ]
    }
  ]
}